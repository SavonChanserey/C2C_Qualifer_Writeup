#!/usr/bin/env python3
"""
Lucky Slots - MULTI-CORE PARALLEL Exploit (Fixed)
Uses all available CPU cores to search much faster!
Automatically handles both HTTP and HTTPS
"""

import requests
import time
import sys
from multiprocessing import Pool, cpu_count
from typing import List, Optional


class DotNetRandom:
    """Minimal .NET Random"""
    MBIG = 2147483647
    
    def __init__(self, seed: int):
        seed = seed & 0xFFFFFFFF
        if seed >= 2**31:
            seed -= 2**32
        
        MSEED = 161803398
        subtraction = (MSEED - abs(seed)) % self.MBIG
        
        self._seed_array = [0] * 56
        self._seed_array[55] = subtraction
        
        mk = 1
        for i in range(1, 55):
            ii = (21 * i) % 55
            self._seed_array[ii] = mk
            mk = (subtraction - mk) % self.MBIG
            subtraction = self._seed_array[ii]
        
        for _ in range(4):
            for i in range(1, 56):
                self._seed_array[i] = (self._seed_array[i] - 
                                      self._seed_array[1 + (i + 30) % 55]) % self.MBIG
        
        self._inext = 0
        self._inextp = 21
    
    def internal_sample(self) -> int:
        self._inext = (self._inext + 1) % 56
        if self._inext == 0:
            self._inext = 1
        self._inextp = (self._inextp + 1) % 56
        if self._inextp == 0:
            self._inextp = 1
        
        retval = (self._seed_array[self._inext] - self._seed_array[self._inextp]) % self.MBIG
        self._seed_array[self._inext] = retval
        return retval
    
    def next_int(self, min_val: int = 0, max_val: int = None) -> int:
        if max_val is None:
            max_val = self.MBIG
        range_size = max_val - min_val
        sample = self.internal_sample()
        return int(sample * (1.0 / self.MBIG) * range_size) + min_val
    
    def next_bytes(self, buffer: bytearray):
        for i in range(len(buffer)):
            buffer[i] = self.internal_sample() % 256


def generate_tick(rng: DotNetRandom) -> dict:
    """Generate one tick"""
    reels = [rng.next_int(0, 10) for _ in range(3)]
    jackpot = rng.next_int(0, 1000000)
    samples = [rng.next_int(0, 2147483647) for _ in range(16)]
    buf = bytearray(4)
    rng.next_bytes(buf)
    redeem = rng.next_int(0, 10000000)
    
    return {
        'reels': reels,
        'jackpot': jackpot,
        'samples': samples,
        'redeem': redeem
    }


def check_seed(args):
    """Worker function to check a single seed"""
    seed, frames = args
    
    try:
        rng = DotNetRandom(seed)
        
        # Warmup
        buf = bytearray(64)
        rng.next_bytes(buf)
        rng.next_int(0, 1000000)
        rng.next_int(0, 2147483647)
        
        # Try different offsets
        for offset in range(min(5, len(frames) + 2)):
            test_rng = DotNetRandom(seed)
            buf2 = bytearray(64)
            test_rng.next_bytes(buf2)
            test_rng.next_int(0, 1000000)
            test_rng.next_int(0, 2147483647)
            
            for _ in range(offset):
                generate_tick(test_rng)
            
            # Check match with first frame
            gen = generate_tick(test_rng)
            
            if (gen['reels'] == frames[0]['reels'] and
                gen['jackpot'] == frames[0]['jackpotPreview']):
                
                # Strong match - verify with samples
                if gen['samples'][:4] == frames[0]['sampleInts'][:4]:
                    # Verify with second frame if available
                    if len(frames) > 1:
                        gen2 = generate_tick(test_rng)
                        if gen2['reels'] == frames[1]['reels']:
                            return (seed, offset)
                    else:
                        return (seed, offset)
    except:
        pass
    
    return None


def parallel_search(frames: List[dict], start: int, end: int, num_workers: int = None):
    """Search range using multiprocessing"""
    
    if num_workers is None:
        num_workers = cpu_count()
    
    print(f"[*] Using {num_workers} CPU cores")
    print(f"[*] Search range: {start:,} to {end:,} ({end-start:,} seeds)")
    print(f"[*] Estimated time: {(end-start) / num_workers / 1_000_000:.1f} minutes\n")
    
    # Create argument list
    args_list = [(seed, frames) for seed in range(start, end)]
    
    # Progress tracking
    total = len(args_list)
    chunk_size = max(1, total // (num_workers * 10))
    
    with Pool(num_workers) as pool:
        for i, result in enumerate(pool.imap_unordered(check_seed, args_list, chunksize=chunk_size)):
            if result:
                print(f"\n[+] FOUND! Seed={result[0]}, Offset={result[1]}")
                pool.terminate()
                return result
            
            if (i + 1) % 100_000 == 0:
                progress = (i + 1) / total * 100
                print(f"    Progress: {i+1:,}/{total:,} ({progress:.1f}%)", end='\r', flush=True)
    
    print(f"\n[!] Not found in range")
    return None


def smart_fetch(url: str, timeout: int = 10):
    """Try to fetch with automatic HTTP/HTTPS detection"""
    try:
        resp = requests.get(url, timeout=timeout)
        resp.raise_for_status()
        return resp, url.split('/')[0] + '//' + url.split('/')[2]  # Return base URL
    except requests.exceptions.SSLError:
        # Try HTTP instead
        http_url = url.replace('https://', 'http://')
        resp = requests.get(http_url, timeout=timeout)
        resp.raise_for_status()
        return resp, http_url.split('/')[0] + '//' + http_url.split('/')[2]


def multi_core_exploit(base_url: str):
    """Main exploit with multi-core search"""
    print("="*70)
    print(f"LUCKY SLOTS - PARALLEL SEARCH ({cpu_count()} cores available)")
    print("="*70)
    
    # Fetch frames with automatic protocol detection
    print("\n[1] Fetching frames...")
    try:
        resp, actual_base = smart_fetch(f"{base_url}/api/recent/10")
        frames = resp.json()
        base_url = actual_base  # Update to the working protocol
    except Exception as e:
        print(f"[!] Failed to fetch frames: {e}")
        return False
    
    print(f"[+] Connected to: {base_url}")
    print(f"[+] Got {len(frames)} frames (ticks {frames[0]['tickId']}-{frames[-1]['tickId']})")
    
    # Search in stages from most likely to least likely ranges
    print("\n[2] Searching for seed (prioritizing likely ranges)...")
    
    search_stages = [
        (0, 5_000_000, "0-5M (very common in CTFs)"),
        (5_000_000, 10_000_000, "5M-10M"),
        (-5_000_000, 0, "-5M to 0"),
        (-10_000_000, -5_000_000, "-10M to -5M"),
        (10_000_000, 50_000_000, "10M-50M (uncommon)"),
        (-50_000_000, -10_000_000, "-50M to -10M"),
    ]
    
    found = None
    
    for start, end, desc in search_stages:
        print(f"\n[*] Stage: {desc}")
        result = parallel_search(frames, start, end)
        
        if result:
            found = result
            break
    
    if not found:
        print("\n[!] Seed not found in prioritized ranges.")
        print("[!] You can expand the search or let it run longer.")
        return False
    
    seed, offset = found
    print(f"\n[+] Seed recovered: {seed}")
    
    # Predict next tick
    print("\n[3] Predicting next tick...")
    resp, _ = smart_fetch(f"{base_url}/api/frame")
    current = resp.json()
    current_tick = current['tickId']
    
    print(f"[+] Current tick: {current_tick}")
    
    rng = DotNetRandom(seed)
    buf = bytearray(64)
    rng.next_bytes(buf)
    rng.next_int(0, 1000000)
    rng.next_int(0, 2147483647)
    
    for _ in range(current_tick):
        generate_tick(rng)
    
    next_tick = generate_tick(rng)
    
    print(f"[+] Next tick {current_tick + 1} prediction:")
    print(f"    Reels: {next_tick['reels']}")
    print(f"    Redeem: {next_tick['redeem']}")
    
    # Wait and submit
    print("\n[4] Waiting for next tick...")
    time.sleep(2.5)
    
    print("[5] Submitting...")
    try:
        resp = requests.post(
            f"{base_url}/api/redeem",
            json={"tickId": current_tick + 1, "code": next_tick['redeem']},
            timeout=10
        )
        result = resp.json()
    except requests.exceptions.SSLError:
        # Try HTTP
        http_base = base_url.replace('https://', 'http://')
        resp = requests.post(
            f"{http_base}/api/redeem",
            json={"tickId": current_tick + 1, "code": next_tick['redeem']},
            timeout=10
        )
        result = resp.json()
    
    print("\n" + "="*70)
    if result.get('success'):
        print("üéâ SUCCESS! üéâ")
        print("="*70)
        print(f"\nFLAG: {result['flag']}\n")
    else:
        print("‚ùå FAILED")
        print("="*70)
        print(f"Error: {result.get('message')}")
    
    return result.get('success', False)


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print(f"Usage: python3 parallel_exploit_fixed.py <url>")
        print(f"Example: python3 parallel_exploit_fixed.py challenges.1pc.tf:24927")
        print(f"\nYour system has {cpu_count()} CPU cores")
        sys.exit(1)
    
    url = sys.argv[1].rstrip('/')
    
    # Try HTTPS first, will auto-fallback to HTTP
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    print(f"[*] Target: {url}")
    print(f"[*] CPU cores: {cpu_count()}\n")
    
    try:
        multi_core_exploit(url)
    except KeyboardInterrupt:
        print("\n[!] Interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n[!] Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
